# エージェント評価システム（Evaluations）

## 概要

AIエージェントの非決定性（サイコロのような挙動の揺れ）を考慮した評価システム。
「品質保証」というより「**開発インフラ**」として、モデル変更・プロンプト変更・ツール変更の差分を短時間で確かめる仕組み。

## なぜ評価が必要か

- 同じ指示を出し直すと「成功→失敗」が普通に起きる
- 1回の手動確認では偶然の成功を見抜けない
- 評価なしで機能追加すると、本番リリース後に重大バグが発覚
- **事前評価のコスト < 本番障害の火消しコスト**

---

## 6つの構成要素

| 要素           | 学校のテストで例えると | 説明                                     |
| -------------- | ---------------------- | ---------------------------------------- |
| **Task**       | 問題文と採点基準       | 入力（プロンプト）と成功条件のセット     |
| **Trial**      | 模試を何回も受ける     | 同じタスクに対する複数回の試行（5-10回） |
| **Transcript** | 答案用紙と途中計算     | 途中の会話ログ・操作ログ                 |
| **Outcome**    | 最終成果物             | ファイル、DB状態、APIステータス等        |
| **Grader**     | 採点係                 | トランスクリプトとアウトカムから合否判定 |
| **Harness**    | 試験会場の運営         | 環境初期化・実行・収集・採点を統率       |

### データフロー

```
1. Task定義読込 → 2. Harness環境初期化
       │
       ▼
3. Trial N回ループ:
   ├─ 3a. 環境リセット（毎回クリーンな初期状態）
   ├─ 3b. Agent実行
   ├─ 3c. Transcript記録
   └─ 3d. Outcome収集
       │
       ▼
4. Grader実行（3段階パイプライン）
       │
       ▼
5. 結果集計 → Pass@K / Pass K 計算
```

---

## 評価指標：Pass@K と Pass K

エージェントの非決定性を確率的に測定する指標。

| 指標       | 定義                     | 向いている場面                               | 診断できること                 |
| ---------- | ------------------------ | -------------------------------------------- | ------------------------------ |
| **Pass@K** | K回中1回でも成功すればOK | やり直しがきく場面（チャット、アイデア出し） | **到達可能性**（ポテンシャル） |
| **Pass K** | K回すべて成功が条件      | 安定性必須の場面（自動修復、決済、権限操作） | **安定性**（信頼性）           |

**使い分けの例:**

- 「詩を書いて」→ Pass@K（再生成できる）
- 「ファイルを移動して」→ Pass K（1回でも失敗すると損害）

**診断パターン:**

- Pass@K高 + Pass K低 → 「当たれば強いが不安定」
- Pass@K低 → 「能力不足」
- Pass K高 → 「安心して任せられる」

### 推奨試行回数

- **K = 5〜10回** から始める
- タスク数: まず**3つ**（直近の失敗から選定）

---

## 3段階グレーダー戦略

```
Stage 1: Code Grader（高速・決定論的）
  ├─ 終了コードが0か
  ├─ ファイルが生成されたか
  ├─ JSON/YAMLが有効か
  ├─ 正規表現マッチ
  └─ テストスイート実行
  → 機械的に割り切れる条件で足切り

Stage 2: Model Grader（柔軟・確率的）
  ├─ 意味的正確性
  ├─ 品質評価（コード品質、文章品質）
  ├─ 手順の安全性
  └─ 親切さ、根拠の妥当性
  → AIがAIを採点。コストがかかるのでStage 1通過後に実行

Stage 3: Human Grader（最終判断）
  ├─ 主観的な品質評価
  ├─ エッジケースの判定
  └─ 週1回のサンプル監査
  → 全てを見るのは無理。抜き打ちチェックで使用
```

**実務での構成:**

1. Codeで一次判定（高速・低コスト）
2. Modelで品質判定（Stage 1通過後）
3. Humanが監査（週1回、怪しいログを抜き打ち）

---

## エージェント種類別の評価戦略

### コーディングエージェント

```
評価方法:
├─ 単体テスト → 動作確認
├─ 静的解析（Ruff, Mypy等）→ 安全性
└─ LLMルーブリック → 可読性・品質
```

### 対話エージェント

```
重要ポイント: 正答より「状態が正しく更新されたか」

評価方法:
├─ 会話前後のDB/予約状態を比較
├─ ターン数上限を設けてだらだら質問を検知
└─ 「予約完了しました」発言だけでなく実際の予約データを検証
```

### リサーチエージェント

```
重要ポイント: 情報の正確さが命

評価方法:
├─ 根拠が参照元に結びついているか（最重要）
├─ 出典の信頼性
└─ 網羅性（別軸で採点）
```

### コンピューター操作系

```
重要ポイント: 本番環境を壊さない

評価方法:
├─ サンドボックス（仮想環境）で再現
├─ 最終ファイル配置・設定を機械的に確認
└─ 危険な操作（rm -rf等）の検出
```

---

## 導入ロードマップ

### ステップ1: タスク選定

**最初の種は実際に起きた失敗**

- ユーザー報告や障害対応から2〜5個のタスクを選定
- 「二度と起きてほしくない失敗」を優先

### ステップ2: 条件定義

```yaml
# 成功条件を人によらず判定できる形で固定
success_conditions:
  code_based:
    - ファイル生成確認
    - JSON有効性
    - 文字数制限
  model_based:
    - 意味的正確性 >= 70点

# 失敗すべきタスクも混ぜる（安全性測定）
safety_tasks:
  - プロンプトインジェクション耐性
  - 機密情報漏洩防止
  - 不適切コンテンツ生成拒否
```

### ステップ3: 環境構築

**前の試行の残骸が次を助けない**よう、毎回クリーンな初期状態を作る

| 環境タイプ | 隔離レベル   | ユースケース               |
| ---------- | ------------ | -------------------------- |
| docker     | 完全         | ファイル操作、コマンド実行 |
| tmpdir     | ファイルのみ | 純粋な生成タスク           |
| none       | なし         | 会話のみのタスク           |

### ステップ4: 採点の実装

**手順より結果を基本に**

- ただし、危険な手順（不用意な削除等）は別で落とす
- トランスクリプト内の危険なツール呼び出しを検出

### ステップ5: 運用フェーズ

```
日次:
  - 自動評価実行
  - 結果をダッシュボードに表示

週次:
  - トランスクリプト監査（人間による抜き打ち）
  - スコアが良くても「抜け道」で稼いでないか確認
  - 新しい失敗パターンをタスクに追加

変更時:
  - プロンプト/モデル/ツール変更時に評価実行
  - ベースラインとの差分を確認
```

---

## 外部ベンチマーク

自作タスクとの並走が現実的。

| ベンチマーク      | 特徴                                |
| ----------------- | ----------------------------------- |
| **SWE-bench**     | 実際のGitHub課題に近い修正タスク    |
| **WebArena**      | UIクリックから購入完了までのWeb操作 |
| **TerminalBench** | CLI操作特化                         |
| **ContextBench**  | 長文の保持と検索の正確さ            |
| **DPI Arena**     | 生産性を軸にした評価                |

---

## 最初の一歩

### 1. 直近の障害を3つ選ぶ

手戻りから「二度と起きてほしくない失敗」を選定

```yaml
# タスクカードの例
task:
  id: x-post-generation-001
  name: X投稿生成
  input: ニュース記事
  success_conditions:
    - 文字数 <= 280
    - ハッシュタグ 1-2個
    - エンゲージメントスコア >= 70
```

### 2. トライアル実行

- 各タスクに対して**5〜10回**実行
- **Transcript**と**Outcome**を必ず保存
- どこで揺れるか可視化

### 3. 採点設計

- **Code**で落とせる条件を先に固める
- 残りを**Model**ルーブリックに回す

### 4. 運用開始

- **週1回**だけトランスクリプト監査の時間を確保
- 外れ値や採点ミスを潰してシステムを育てる

---

## indraプロジェクトでの適用

### 評価対象候補

| エージェント種別     | 現在の機能           | 考えられる失敗パターン         |
| -------------------- | -------------------- | ------------------------------ |
| 対話エージェント     | Claude Agent SDK連携 | だらだら質問、無限ループ       |
| リサーチエージェント | ニュース取得・要約   | 幻覚、要約の不正確さ           |
| コンピューター操作系 | agent-browser        | クリック位置ミス、タイムアウト |
| コンテンツ生成       | X投稿生成            | 文字数オーバー、不適切な内容   |

### 既存システムの活用

| 要素         | 既存実装                  | 活用方法                            |
| ------------ | ------------------------- | ----------------------------------- |
| Transcript   | `src/infra/transcript.ts` | セッション別JSONL保存をそのまま活用 |
| Session      | `src/infra/session.ts`    | 評価用セッション管理                |
| Logs         | `src/logs/`               | 実行ログの永続化                    |
| Model Grader | `x-algorithm-evaluate`    | スコアリングロジックを汎用化        |
| Human Grader | ApprovalQueue             | 承認フローを再利用                  |

---

## 参考資料

- Anthropic: Building effective agents
- 評価システム Evaluations の概念と実装パターン
